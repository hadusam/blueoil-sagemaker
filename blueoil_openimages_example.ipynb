{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Blueoil on Amazon SageMaker\n",
    "## Docker build and push (to Amazon ECR)\n",
    "https://github.com/hadusam/blueoil-sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!bash ./docker_push_ecr.sh blueoil-sagemaker blueoil/blueoil:v0.22.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data (upload a face images subset of OpenimagesV4 to Amazon S3)\n",
    "### Create sagemaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def upload_data(sess, path, key_prefix='data', compress=False):\n",
    "    if compress:\n",
    "        path = shutil.make_archive(path, 'gztar', '.', path)\n",
    "    s3_data = sess.upload_data(path=path, key_prefix=key_prefix)\n",
    "    return s3_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a face image subset of OpenimagesV4 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!curl -O https://s3-ap-northeast-1.amazonaws.com/leapmind-public-storage/datasets/openimages_face.tgz\n",
    "!tar xf openimages_face.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_data = upload_data(sess, 'openimages_face', compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing config (upload to Amazon S3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create config file\n",
    "https://docs.blueoil.org/tutorial/image_det.html\n",
    "\n",
    "create `openimages_face_sample.py` \n",
    "\n",
    "by \n",
    "```\n",
    "blueoil init -o openimages_face_sample.py\n",
    "```\n",
    "with\n",
    "```\n",
    "dataset:\n",
    "  format: OpenImagesV4\n",
    "  train dataset path: /opt/ml/input/data/dataset/openimages_face/\n",
    "  validation dataset path: /opt/ml/input/data/dataset/openimages_face/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "config_data = upload_data(sess, 'openimages_face_sample.py', key_prefix='config', compress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve data location\n",
    "\n",
    "# train_data  = 's3://' + sagemaker.Session().default_bucket() + '/data/openimages_face.tar.gz'\n",
    "# config_data += 's3://' + sagemaker.Session().default_bucket() + '/config/openimages_face_sample.yml'\n",
    "print(config_data)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Amazon Sagemaker on-demand instance\n",
    "#### Launch training instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "algorithm_name = 'blueoil-sagemaker'\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "region = my_session.region_name\n",
    "\n",
    "ecr_image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run train and convert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "train_instance_type = 'ml.p2.xlarge'\n",
    "\n",
    "estimator = Estimator(\n",
    "    image_name=ecr_image, \n",
    "    role=sagemaker.get_execution_role(), \n",
    "    train_instance_count=1, \n",
    "    train_instance_type=train_instance_type, \n",
    "    hyperparameters={\n",
    "        'config': '/opt/ml/input/data/config/openimages_face_sample.py', \n",
    "        'experiment_id': 'objectdetection_face_sample'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator.fit({'dataset': train_data, 'config': config_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download converted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp $estimator.model_data ./\n",
    "!tar zxf model.tar.gz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "notice": "Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
